# Ollama Configuration
# URL where Ollama is running (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# Model to use (default: llama2-uncensored)
OLLAMA_MODEL=llama2-uncensored

# Server Port
PORT=5002
