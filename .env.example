# ===== Ollama Configuration =====
OLLAMA_URL=http://localhost:11434

# Which Ollama model to use for chat responses
OLLAMA_MODEL=llama2-uncensored

# ===== Server Configuration =====
PORT=5002

# ===== Optional: Advanced Configuration =====
# REQUEST_TIMEOUT=120000

# Log level for debugging
# Options: error, warn, info, debug
# NODE_ENV=development
